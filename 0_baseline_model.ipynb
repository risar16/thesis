{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import pickle\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# setting directory\n",
    "os.chdir('K:\\Specialemappe_XD1')\n",
    "\n",
    "# load labelled sample\n",
    "load_sample=pd.read_excel('labelled_sample.xlsx')\n",
    "load_sample.columns\n",
    "\n",
    "# identify any NaN values\n",
    "load_sample.isnull().values.any()\n",
    "\n",
    "# deleting 187 instances not recognized by educational institutions or with mixed classes\n",
    "load_sample.drop(load_sample.loc[load_sample['instances_to_discard']=='delete'].index, inplace=True)\n",
    "\n",
    "# data dropping drop useless columns\n",
    "df = load_sample.drop(columns=['Unnamed: 0', 'index', 'instances_to_discard'])\n",
    "df.columns\n",
    "\n",
    "# count instances per classes\n",
    "df['set_label'].value_counts()\n",
    "\n",
    "# set interested classes with integer labels \n",
    "df.loc[df['set_label'] == 'dansk', 'set_label'] = 1\n",
    "df.loc[df['set_label'] == 'idræt', 'set_label'] = 2\n",
    "df.loc[df['set_label'] == 'matematik', 'set_label'] = 3\n",
    "df.loc[df['set_label'] == 'temporary', 'set_label'] = 4\n",
    "df.loc[df['set_label'] == 'other', 'set_label'] = 0\n",
    "\n",
    "# set all other classes as the class '0'\n",
    "df['set_label'] = np.where(\n",
    "    (df['set_label'] !=1) & (df['set_label'] !=2) & (df['set_label'] !=3) & (df['set_label'] !=4), 0, df['set_label'])\n",
    "\n",
    "# class imbalance \n",
    "df['set_label'].value_counts() \n",
    "\n",
    "# cleaning data\n",
    "char_noise = r'[-_()\\\"#@;:`.''!?*´.:;,<>=+^Â/]'\n",
    "digit_noise= r'[0123456789]'\n",
    "\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: re.sub(char_noise, ' ', x))\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: re.sub(digit_noise, '', x))\n",
    "\n",
    "# # delete artficially created double whitespaces\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: x.replace('  ', ' '))\n",
    "# # needed a 2nd time\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: x.replace('  ', ' '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing corpus for gensim implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create sentence list from labels\n",
    "\n",
    "# hints from https://stackoverflow.com/q/60852962\n",
    "\n",
    "list_activities = []\n",
    "\n",
    "class my_corpus():\n",
    "    \n",
    "    def __init__(self, list_activities):\n",
    "        self.list_pseudo_activities = list()\n",
    "        self.run = 0\n",
    "\n",
    "        for string in list_activities:\n",
    "            list_pseudo_strings = list()\n",
    "            \n",
    "            for i in range(len(string)-1):\n",
    "                list_pseudo_strings.append(string[i:i+2])\n",
    "            \n",
    "            self.list_pseudo_activities.append(list_pseudo_strings)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        now = datetime.now().strftime('%H:%M:%S')\n",
    "        print(f'The data-iteration starts {self.run} at : {now}')\n",
    "        print('------')\n",
    "        \n",
    "        for pseudo_strings in self.list_pseudo_activities:\n",
    "            pseudo_abbreviations = pseudo_strings\n",
    "            yield pseudo_abbreviations\n",
    "        self.run += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% hints from https://www.oreilly.com/library/view/fasttext-quick-start/9781789130997/f74fb462-a846-4569-af56-af9395eb2acf.xhtml\n",
    "# hints from https://stackoverflow.com/a/54891714\n",
    "\n",
    "# gensim implements callbacck parameter which takes sequence of subclasses of CallbackAny2Vec\n",
    "\n",
    "class callback(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        epoch_end_time = datetime.now().strftime('%H:%M:%S')\n",
    "        print(f'Epoch ends at : {epoch_end_time}')\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Embedding with averaging 2-gram: the single instances are split in elements of 2 characters\n",
    "\n",
    "def embedding_train(corpus_object):\n",
    "    dict_pseudo_string = dict()\n",
    "    \n",
    "    for string in corpus_object:\n",
    "        mean_vec_string = np.array([0]*w2v_train.vector_size, dtype='float32')\n",
    "        count = 0      \n",
    "        \n",
    "        for i in range(len(string)-1):\n",
    "            count += 1\n",
    "            mean_vec_string += w2v_train.wv[string[i:i+2]] # splitting in 2 characters\n",
    "        \n",
    "        dict_pseudo_string[string] = mean_vec_string/count # averaging\n",
    "        \n",
    "    return dict_pseudo_string\n",
    "\n",
    "\n",
    "def embedding_val(corpus_object):\n",
    "    dict_pseudo_string = dict()\n",
    "    \n",
    "    for string in corpus_object:\n",
    "        mean_vec_string = np.array([0]*w2v_val.vector_size, dtype='float32')\n",
    "        count = 0      \n",
    "        \n",
    "        for i in range(len(string)-1):\n",
    "            count += 1\n",
    "            mean_vec_string += w2v_val.wv[string[i:i+2]]\n",
    "        \n",
    "        dict_pseudo_string[string] = mean_vec_string/count\n",
    "        \n",
    "    return dict_pseudo_string\n",
    "\n",
    "\n",
    "def embedding_test(corpus_object):\n",
    "    dict_pseudo_string = dict()\n",
    "    \n",
    "    for string in corpus_object:\n",
    "        mean_vec_string = np.array([0]*w2v_test.vector_size, dtype='float32')\n",
    "        count = 0      \n",
    "        \n",
    "        for i in range(len(string)-1):\n",
    "            count += 1\n",
    "            mean_vec_string += w2v_test.wv[string[i:i+2]]\n",
    "        \n",
    "        dict_pseudo_string[string] = mean_vec_string/count\n",
    "        \n",
    "    return dict_pseudo_string\n",
    "\n",
    "\n",
    "def embedding_10samples(corpus_object):\n",
    "    dict_pseudo_string = dict()\n",
    "    \n",
    "    for string in corpus_object:\n",
    "        mean_vec_string = np.array([0]*w2v_10samples.vector_size, dtype='float32')\n",
    "        count = 0      \n",
    "        \n",
    "        for i in range(len(string)-1):\n",
    "            count += 1\n",
    "            mean_vec_string += w2v_10samples.wv[string[i:i+2]]\n",
    "        \n",
    "        dict_pseudo_string[string] = mean_vec_string/count\n",
    "        \n",
    "    return dict_pseudo_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data and embedding with Word2Vec - Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% splitting data in train, validation and test set\n",
    "\n",
    "# function splitting data\n",
    "def train_val_test(text,cutoffs=[0.8,0.9]):\n",
    "    train = text[:int(len(text)*cutoffs[0])]\n",
    "    val = text[int(len(text)*cutoffs[0]):int(len(text)*cutoffs[1])]\n",
    "    test = text[int(len(text)*cutoffs[1]):]\n",
    "    return train, val, test\n",
    "\n",
    "train_content, val_content, test_content = train_val_test(df)\n",
    "train_content['set_label'].value_counts()   #  >654 per class\n",
    "val_content['set_label'].value_counts()     # >71 perr class\n",
    "test_content['set_label'].value_counts()    # >85 per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data : remove duplicates, 2-gram, embedding, new dataframe train\n",
    "duplicates_in_train = train_content[train_content.duplicated(['name_activity'])]\n",
    "train_set = train_content.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['name_activity'], keep='first')\n",
    "train_list_activities = train_set['name_activity'].to_list()\n",
    "train_strings_ngram = my_corpus(train_list_activities)\n",
    "# word2vec train data\n",
    "w2v_train = Word2Vec(train_strings_ngram, vector_size= 5, window=5, min_count=1, workers=4, sg=1,\n",
    "                  compute_loss=True, callbacks=[callback()])\n",
    "# w2v_train.save('models/w2v_train_size20_w5_skipgram.model')\n",
    "\n",
    "dict_pseudo_strings_w2v_train = embedding_train(train_list_activities)\n",
    "\n",
    "\n",
    "# validation data : remove duplicates, 2-gram, embedding, new dataframe validation\n",
    "duplicates_in_validation = val_content[val_content.duplicated(['name_activity'])]\n",
    "val_set = val_content.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['name_activity'], keep='first')\n",
    "val_list_activities = val_set['name_activity'].to_list()\n",
    "val_strings_ngram = my_corpus(val_list_activities)\n",
    "# word2vec validation data\n",
    "w2v_val = Word2Vec(val_strings_ngram, vector_size= 5, window=5, min_count=1, workers=4, sg=1,\n",
    "                  compute_loss=True, callbacks=[callback()])\n",
    "# w2v_val.save('models/w2v_val_size20_w5_skipgram.model')\n",
    "\n",
    "dict_pseudo_strings_w2v_val = embedding_val(val_list_activities)\n",
    "\n",
    "\n",
    "# test data : remove duplicates, 2-gram, embedding, new dataframe test\n",
    "duplicates_in_test = test_content[test_content.duplicated(['name_activity'])]\n",
    "test_set = test_content.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['name_activity'], keep='first')\n",
    "test_list_activities = test_set['name_activity'].to_list()\n",
    "test_strings_ngram = my_corpus(test_list_activities)\n",
    "# word2vec test data\n",
    "w2v_test = Word2Vec(test_strings_ngram, vector_size= 5, window=5, min_count=1, workers=4, sg=1,\n",
    "                  compute_loss=True, callbacks=[callback()])\n",
    "# w2v_test.save('models/w2v_test_size20_w5_skipgram.model')\n",
    "\n",
    "dict_pseudo_strings_w2v_test = embedding_test(test_list_activities)\n",
    "\n",
    "# 10 samples data : remove duplicates, 2-gram, embedding, new dataframe 10 samples\n",
    "duplicates_in_10samples = df10[df10.duplicated(['name_activity'])]\n",
    "df10_set = df10.apply(lambda x: x.astype(str).str.lower()).drop_duplicates(subset=['name_activity'], keep='first')\n",
    "df10_set_list_activities = df10_set['name_activity'].to_list()\n",
    "df10_strings_ngram = my_corpus(df10_set_list_activities)\n",
    "# word2vec train data\n",
    "w2v_10samples = Word2Vec(df10_strings_ngram, vector_size= 5, window=5, min_count=1, workers=4, sg=1,\n",
    "                  compute_loss=True, callbacks=[callback()])\n",
    "# w2v_10samples.save('models/w2v_10samples_size20_w5_skipgram.model')\n",
    "\n",
    "dict_pseudo_strings_w2v_10samples = embedding_10samples(df10_set_list_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% preparing train set, validation set and test set\n",
    "\n",
    "# dataframe of pseudo n-gram and embedding\n",
    "train_pseudo_set =pd.DataFrame.from_dict(dict_pseudo_strings_w2v_train, orient=\"index\")\n",
    "val_pseudo_set =pd.DataFrame.from_dict(dict_pseudo_strings_w2v_val, orient=\"index\")\n",
    "test_pseudo_set =pd.DataFrame.from_dict(dict_pseudo_strings_w2v_test, orient=\"index\")\n",
    "samples_pseudo_set =pd.DataFrame.from_dict(dict_pseudo_strings_w2v_10samples, orient=\"index\")\n",
    "\n",
    "# NaN values present in all the sets\n",
    "train_pseudo_set.isnull().sum().sum()\n",
    "val_pseudo_set.isnull().sum().sum()\n",
    "test_pseudo_set.isnull().sum().sum()\n",
    "samples_pseudo_set.isnull().sum().sum()\n",
    "\n",
    "# train set, validation set and test set\n",
    "x_train = train_pseudo_set.fillna(train_pseudo_set.mean())\n",
    "y_train = train_set['set_label']\n",
    "\n",
    "x_val = val_pseudo_set.fillna(val_pseudo_set.mean())\n",
    "y_val = val_set['set_label']\n",
    "\n",
    "x_test = test_pseudo_set.fillna(test_pseudo_set.mean())\n",
    "y_test = test_set['set_label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFIER : KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # create KNN Object\n",
    "model_knn = KNeighborsClassifier(algorithm = 'ball_tree', leaf_size =30, metric = 'euclidean', \n",
    "                                  n_jobs = 1, n_neighbors = 3, p = 1, weights = 'distance')\n",
    "\n",
    "\n",
    "# training model\n",
    "model_knn.fit(x_train, y_train)\n",
    "\n",
    "# predict on train set\n",
    "pred_knn_train = model_knn.predict(x_train)\n",
    "\n",
    "# predict on validation set\n",
    "pred_knn_val = model_knn.predict(x_val)\n",
    "\n",
    "# predict on test set\n",
    "pred_knn_test = model_knn.predict(x_test)\n",
    "\n",
    "f1_knn_train = f1_score(y_train, pred_knn_train, average='macro')\n",
    "print(\"KNN F1-Score train_set:\", round(f1_knn_train, 4),\"\\n\")\n",
    "# print(classification_report(y_train, pred_knn_train))\n",
    "\n",
    "f1_knn_val = f1_score(y_val, pred_knn_val, average='macro')\n",
    "print(\"KNN F1-Score val_set:\", round(f1_knn_val, 4),\"\\n\")\n",
    "print(classification_report(y_val, pred_knn_val))\n",
    "\n",
    "f1_knn_test = f1_score(y_test, pred_knn_test, average='macro')\n",
    "print(\"KNN F1-Score test_set:\", round(f1_knn_test, 4),\"\\n\")\n",
    "print(classification_report(y_test, pred_knn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 10 , window 5\n",
    "# KNN F1-Score train_set: 0.8595 \n",
    "# KNN F1-Score val_set: 0.1932 \n",
    "# KNN F1-Score test_set: 0.1932 \n",
    "\n",
    "# size 20 , window 5\n",
    "# KNN F1-Score train_set: 0.8804 \n",
    "# KNN F1-Score val_set: 0.1825 \n",
    "# KNN F1-Score test_set: 0.1892 \n",
    "\n",
    "# size 50, window 5 \n",
    "# KNN F1-Score train_set: 0.8864 \n",
    "# KNN F1-Score val_set: 0.1824 \n",
    "# KNN F1-Score test_set: 0.1913 \n",
    "\n",
    "# size 10 , window 3\n",
    "# KNN F1-Score train_set: 0.8577 \n",
    "# KNN F1-Score val_set: 0.1865 \n",
    "# KNN F1-Score test_set: 0.2018 \n",
    "\n",
    "# size 20 , window 3\n",
    "# KNN F1-Score train_set: 0.8815 \n",
    "# KNN F1-Score val_set: 0.2234  ##\n",
    "# KNN F1-Score test_set: 0.1845 \n",
    "\n",
    "# size 50, window 3\n",
    "# KNN F1-Score train_set: 0.8867 \n",
    "# KNN F1-Score val_set: 0.1838 \n",
    "# KNN F1-Score test_set: 0.2381 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search knn \n",
    "\n",
    "# grid search for knn - size 20 , window 3 \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "n_k= [1,3,5,7,9,12,15,20, 25, 30]\n",
    "alg = ['ball_tree', 'kd_tree']\n",
    "weights_modality = ['uniform' , 'distance']\n",
    "leaf_n = [30,40]\n",
    "p_n = [1,2,3]\n",
    "metric_type = ['euclidean', 'manhattan', 'mahalanobis']\n",
    "j = [1]\n",
    "\n",
    "param_grid = dict(n_neighbors = n_k, \n",
    "                  algorithm = alg,\n",
    "                  weights = weights_modality,\n",
    "                  leaf_size = leaf_n, \n",
    "                  p = p_n, \n",
    "                  metric = metric_type, \n",
    "                  n_jobs = j)\n",
    "  \n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=5, scoring='f1_macro', return_train_score=False,verbose=2)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(x_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "store_grid_par = grid_search.best_params_\n",
    "store_grid_score = grid_search.best_score_\n",
    "\n",
    "print('Best leaf_size:', grid_search.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best p:', grid_search.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', grid_search.best_estimator_.get_params()['n_neighbors'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
