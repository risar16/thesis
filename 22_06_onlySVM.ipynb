# -*- coding: utf-8 -*-
"""
Created on Wed Jun 22 10:27:21 2022

@author: XD1
"""


#################################################################################

# Before to start make sure that: 

# - NLTK manual installation of NLTK
# - pip install nltk==3.6.5
#   needed downgraded from 3.6.6 to 3.6.5 due to a bug in NLTK that occurs when a 
#   .,? and ! are placed at the beginning of the sentence / string
# - in prompt set NLTK in the environment with: set NLTK_DATA=H:\nltk_data

#################################################################################

# import libraries
import os
import re
import pandas as pd
import numpy as np
import regex
import pickle
import datetime
from datetime import datetime
import itertools

import nltk             
from nltk.corpus import stopwords
from nltk import word_tokenize

from nltk.metrics import ConfusionMatrix
from nltk.classify.scikitlearn import SklearnClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score

# setting directory
os.chdir('K:\Specialemappe_XD1')

# check NLTK´s operativity without the bug encountered with NLTK 3.6.6
check_tokenizer = '.?!Den nuværende sætning er en eksempel til at teste tokenizer og at nå en potentielle bug'
check_nltk_operativity = word_tokenize(check_tokenizer, language= 'danish')
print(check_nltk_operativity)

# load labelled sample with 3 classes, dansk, matematik, idræt and vikar, øvrige
load_sample=pd.read_excel('labelled_sample_kopi_pre_1706.xlsx')

# load labelled sample with 6 classes, dansk, matematik, idræt and vikar, øvrige
# load_sample=pd.read_excel('labelled_sample.xlsx')

load_sample.columns

# identify any NaN values
load_sample.isnull().values.any()

# deleting circa 200 instances not recognized by educational institutions or with mixed classes
rows_to_delete = load_sample.loc[load_sample['instances_to_discard']=='delete']
load_sample.drop(load_sample.loc[load_sample['instances_to_discard']=='delete'].index, inplace=True)
rows_to_delete

#%% our new dataframe to keep going

# data dropping drop useless columns
load_sample.columns
df = load_sample.drop(columns=['Unnamed: 0', 'index', 'instances_to_discard'])
df.columns

# count instances per classes
df['set_label'].value_counts()

# set interested classes with integer labels 
df.loc[df['set_label'] == 'dansk', 'set_label'] = 1
df.loc[df['set_label'] == 'idræt', 'set_label'] = 2
df.loc[df['set_label'] == 'matematik', 'set_label'] = 3
df.loc[df['set_label'] == 'temporary', 'set_label'] = 4
df.loc[df['set_label'] == 'other', 'set_label'] = 0

#%% from 17-06 I labelled well 3 additional classes : billedkunst, engelsk and natur_teknologi

# df.loc[df['set_label'] == 'engelsk', 'set_label'] = 5
# df.loc[df['set_label'] == 'billedkunst', 'set_label'] = 6
# df.loc[df['set_label'] == 'natur_teknologi', 'set_label'] = 7

#%% set all other classes as the class '0'

#label everythin as "øvrige" but dont touch the established classes
# df['set_label'] = np.where(
    # (df['set_label'] !=1) & (df['set_label'] !=2) & (df['set_label'] !=3) & (df['set_label'] !=4), 0, df['set_label'])

df['set_label'] = np.where(
    (df['set_label'] !=1) & (df['set_label'] !=2) & (df['set_label'] !=3) & (df['set_label'] !=4) & (df['set_label'] !=5) & (df['set_label'] !=6) & (df['set_label'] !=7), 0, df['set_label'])
df
# class imbalance 
df['set_label'].value_counts() 
# 0 = 43674, 84.29
# 1 = 888, 1.71
# 2 = 810, 1.56
# 3 = 950, 1.83
# 4 = 5491, 10.59
# 5 
# 6
# 7


#%% inspect short headlines of a subject category to see which style people write them about

#example: class temporary

temp_df = df.loc[(df['set_label'] == 4)] # change the number to inspect all activities in this class
temp_df.reset_index(inplace=True)
temp_pre = temp_df.loc[0:50]
temp_pre=temp_pre.drop(columns=['set_label', 'index'])
temp_pre = temp_pre.rename(columns={
                         'name_activity':'emne_fagbetegnelse'})
# print(temp_pre.to_latex(index=False))  
# print(rows_to_delete.to_latex(index=False))  

print(temp_pre['emne_fagbetegnelse'], end='')


#%% Pre-processing 

# after several tries the § and some numbers are beneficial for the performance
# - _ / Â are most likely to confuse the models and prone to more misclassification errors  

df_to_clean = df


# remove noise
char_noise = r'[-_()\"#@;:`.''!?*´.:;,<>=+^Â/]'
df_to_clean['name_activity']= df_to_clean['name_activity'].apply(lambda x: re.sub(char_noise, ' ', x))
# # remove noise
digit_noise= r'[345678]'
df_to_clean['name_activity']= df_to_clean['name_activity'].apply(lambda x: re.sub(digit_noise, '', x))

# # delete artficially created double whitespaces
df_to_clean['name_activity']= df_to_clean['name_activity'].apply(lambda x: x.replace('  ', ' '))
# after several tries, it is needed a 2nd time
df_to_clean['name_activity']= df_to_clean['name_activity'].apply(lambda x: x.replace('  ', ' '))

# cleaned df 
df_cleaned = df_to_clean


#%% FEATURE EXTRACTION : verify features influencing performance of classifier in noisy and preprocessed case

# Noisy features

# not preprocessed data 
content = df['name_activity']

# text composed by the name of the activites from which word features can be obtained
content_text=[]

# variable containing Danish stopwords
dansk_stopwords = set(stopwords.words('danish'))

for name in content:
    name = name.lower() #lowercasing
    name = re.sub('[-_()\"#@;:`.''!?*´:;,<>=+^]', ' ', name) # substitute with whitespace to make possible a better tokenization
    name = re.sub('[4578]', ' ', name) # substitute with whitespace to make possible a better tokenization
    #tokenizing 
    name = word_tokenize(name, language= 'danish')
    
    for token in name:
        if token != ' ':
            if token != '':
                if token not in dansk_stopwords:
                    content_text.append(token)

print('Example of the output:')
print(content_text[100:150])

# variable containing the most frequent words
distribution_used_words = nltk.FreqDist(w for w in content_text) 

# word features
most_fq_words = nltk.FreqDist(w for w in content_text) 
word_features_400 = list(most_fq_words)[:400]

# additional features based on specific rules
rule_based_features = [
    'matematikkens', 'geogebra', 'ing', 'svø', 'vø', 'svøm',\
    'atletik', 'basket','kids', 'kidsvolley', 'volley', 'motion',\
    'da2','dsa', 'andet','andetsprog', 'dansk andet sprog',\
    '0.', 'børnhave', 'basis', 'basisdansk',\
    'fp9','pf9', 'eksam',\
    'planlægning','a0','16d', '16b', '§16', '§',\
    'ffmat', 'ffdan', 'klassemøde', 'læringssamtale', 'fasa', 'konference'\
    'vej', 'vejledning', 'læsevejledere', 'matematikvejleder', 'idrv', 'matv'\
    'vikar', 'eks'
    'skal ikke', 'kørsel', 'studietur', 'kommunale', 'fælleskommnunal','skoleintro', 'praktik']

#all features in the noisy case
word_features_all = list(itertools.chain(word_features_400, rule_based_features))



# preprocessed features

# variable containing name activities
content_cleaned = df_cleaned['name_activity']

content_text_cleaned=[] # text composed by the name of the activites from which word features can be obtained

dansk_stopwords = set(stopwords.words('danish')) # variable containing Danish stopwords

for name in content_cleaned:
    name = name.lower()
    
    # characters and numbers has been removed but remains §
    # substitute with whitespace to make possible a better tokenization already done
    name = word_tokenize(name, language= 'danish')
    
    for token in name:
        if token != ' ':
            if token != '':
                if token not in dansk_stopwords:
                    content_text_cleaned.append(token)

print('Example of the output:')
print(content_text_cleaned[100:150])

# variable containing the most frequent words
mostfq_word_cleaned = nltk.FreqDist(w for w in content_text_cleaned) 
word_features_cleaned = list(mostfq_word_cleaned)[:400]


# additional RULE BASED features
rule_features_cleaned = [
    'matematikkens', 'geogebra', 'ing', 'svø', 'vø', 'svøm',\
    'atletik', 'basket','kids', 'kidsvolley', 'volley', 'motion',\
    'da', 'dsa', 'andet', 'andetsprog','dansk andet sprog',\
    'børnhave', 'basis', 'basisdansk',\
    'fp','pf', 'eksam',\
    'planlægning', '§',\
    'ffmat', 'ffdan', 'klassemøde', 'læringssamtale', 'fasa', 'konference',\
    'vej', 'vejledning', 'læsevejledere', 'matematikvejleder', 'idrv', 'matv',\
    'vikar', 'eks',\
    'skal ikke', 'kørsel', 'tur', 'studietur', 'kommunale', 'fælleskommnunal','skoleintro', 'praktik']

word_feat_cleaned = list(itertools.chain(word_features_cleaned, rule_features_cleaned))
len(word_feat_cleaned)


# Are we loosing some features between the two ways of selecting feature-sets?
missing_features = [feature for feature in word_features_all if feature not in word_feat_cleaned]
print(missing_features, end='')

# lets use first word_feat_cleaned
#%%  save features 

#saving noisy features 
# with open('all_features', 'wb') as fp:
#     pickle.dump(word_features_all, fp)
# print(word_features_all, end='')

#saving "cleaned features 
# with open('all_features', 'wb') as fp:
#     pickle.dump(word_feat_cleaned, fp)
# print(word_feat_cleaned, end='')

#%% feature selector

# nltk chapter 6  search for right features

def document_features(document, word_features):
    
        document_words = set(document)
        features = {}
        for word in word_features :
            features['contains ({})'.format(word)] = (word in document_words)
        return features

#%% SPLITTING data and datasets building 

#remember that we are already dealing with a random sample

def train_val_test(text,cutoffs=[0.8,0.9]):
    train = text[:int(len(text)*cutoffs[0])]
    val = text[int(len(text)*cutoffs[0]):int(len(text)*cutoffs[1])]
    test = text[int(len(text)*cutoffs[1]):]
    return train, val, test

train_content, val_content, test_content = train_val_test(df_cleaned)
train_content['set_label'].value_counts()   #  >654 per class
val_content['set_label'].value_counts()     # >71 perr class
test_content['set_label'].value_counts()    # >85 per class
 
#training set building TUPLE
train_data_tuple = (train_content['name_activity'], train_content['set_label']) #create dataframe tuple
set_training=[]
counter=0 #used for indexing
for _ in train_data_tuple[0]:
    set_training.append([(i.iloc[counter]) for i in train_data_tuple]) #append name emne and its label as a tuple
    counter+=1

 
#validation set building TUPLE
val_data_tuple = (val_content['name_activity'], val_content['set_label']) #create dataframe tuple
set_validation=[]
counter=0 #used for indexing
for _ in val_data_tuple[0]:
    set_validation.append([(i.iloc[counter]) for i in val_data_tuple]) #append name emne and its label as a tuple
    counter+=1

#test set building TUPLE
test_data_tuple=(test_content['name_activity'], test_content['set_label']) #create dataframe tuple
set_test=[]
counter=0 #used for indexing
for _ in test_data_tuple[0]:
    set_test.append([(i.iloc[counter]) for i in test_data_tuple]) #append name emne and its label as a tuple
    counter+=1

print("Training tuple length:", len(set_training))
print("Validation tuple length:", len(set_validation))
print("Test tuple length:", len(set_test))


train_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_feat_cleaned), label) 
             for w, label in set_training]# Training set - def document_feature on each string and pair with class

val_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_feat_cleaned), label) 
           for w, label in set_validation]# Validation set - def document_feature on each string and pair with class 

test_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_feat_cleaned), label) 
            for w, label in set_test]# Test set - def document_feature on each string and pair with class


#%%
### SVC = SVM linear

#  ensure that you are using the file 'labelled_sample' as input if you work on more than 5 classes

svm_weights = {0: 0.11,1: 0.89, 2: 0.89,3: 0.89, 4: 0.89} # having only 5 classes, which 3 are educational subjects
# svm_weights = {0: 0.11,1: 0.89, 2: 0.89,3: 0.89, 4: 0.89,5: 0.89,6: 0.89,7: 0.89} # having only 8 classes, which 6 are educational subjects


clfSVM_cl = SklearnClassifier(LinearSVC(random_state=10,
                                        C=1.8,
                                        penalty = 'l2',
                                        loss = 'hinge',
                                        multi_class='ovr',
                                        class_weight=svm_weights)).train(train_set)

# performance on validation set
y_val = [(y) for _, y in val_set]
pred_svm_val_cl = [clfSVM_cl.classify(p) for p, _ in val_set]
f1_svm_val = f1_score(y_val, pred_svm_val_cl, average='macro')
print("SVM linear´s F1-Score val_set:", round(f1_svm_val, 4),"\n")
# confusion_matrix(y_val, pred_svm_val)

# classification report needs to specify classes
# target_names = ['0','1','2', '3', '4'] 
target_names = ['0','1','2', '3', '4', '5', '6', '7'] 

print(classification_report(y_val, pred_svm_val_cl, target_names=target_names))

# performance on test set
y_test = [(y) for _, y in test_set]
pred_svm_test_cl = [clfSVM_cl.classify(p) for p, _ in test_set]
f1_svm_test = f1_score(y_test, pred_svm_test_cl, average='macro') 
print("SVM linear´s F1-Score test_set:", round(f1_svm_test, 4),"\n")
# confusion_matrix(y_test, pred_svm_test)
print(classification_report(y_test, pred_svm_test_cl, target_names=target_names))

# # save model
# with open('SVM_cleaned.pickle', 'wb') as f:
#     pickle.dump(clfSVM_cl, f)

#save report into excel table ---> LATEX
report_SVM_cleaned_VAL= classification_report(y_val, pred_svm_val_cl, target_names=target_names,  output_dict=True)
df_SVM_cl_VAL = pd.DataFrame(report_SVM_cleaned_VAL)
# df_SVM_cl_VAL.to_excel('report_SVM_clean_val.xlsx')

report_SVM_cleaned_TEST= classification_report(y_test, pred_svm_test_cl, target_names=target_names, output_dict=True)
df_SVM_cl_TEST = pd.DataFrame(report_SVM_cleaned_TEST)
# df_SVM_cl_TEST.to_excel('report_SVM_clean_test.xlsx')


#%% how many activities occurring equal or more than 500 

#are within this sample? 25.15% 
#are within the training set ? 20%


#this portion of data has been retrieved previously 
load_act500=pd.read_excel('act_occuring_more500.xlsx')

load_act500.columns
df_500 = load_act500.drop(columns=['Unnamed: 0', 'initial_index'])
df_500.columns

name_500 = list(set(df_500['Aktivitet navn'].to_list()))
print(len(name_500))

df_sample = list(set(df['name_activity'].to_list()))

intersection_sample = [name for name in name_500 if name in df_sample]
print(len(intersection_sample))

# how many within the training set? 19.82 %
list_train = list(set(train_content['name_activity'].to_list()))
intersection_train = [name for name in name_500 if name in list_train]
print(len(intersection_train))

#%% study misclassification errors - the model did not predict correctly

#in the case of pre-processed data
val_set_SVM_cl = val_content
val_set_SVM_cl['Predictions'] = pred_svm_val_cl 
val_set_SVM_cl['SVM Errors'] = val_set_SVM_cl['Predictions'] == val_set_SVM_cl['set_label']
SVM_errors_val_cl = val_set_SVM_cl[val_set_SVM_cl['SVM Errors'] == False]
len(SVM_errors_val_cl)

test_set_SVM_cl = test_content
test_set_SVM_cl['Predictions'] = pred_svm_test_cl 
test_set_SVM_cl['SVM Errors'] = test_set_SVM_cl['Predictions'] == test_set_SVM_cl['set_label']
SVM_errors_test_cl = test_set_SVM_cl[test_set_SVM_cl['SVM Errors'] == False]
len(SVM_errors_test_cl)
# save in excel
# SVM_errors_test_cl.to_excel('SVC_errors_testset.xlsx')
# SVM_errors_val_cl.to_excel('SVC_errors_valset.xlsx')


#in the case of noisy data
# how many within the miclassification errors made by svm NOT CLEANED?

# validation set 
# val_set_SVM = val_content
# val_set_SVM['Predictions'] = pred_svm_val
# val_set_SVM['SVM Errors'] = val_set_SVM['Predictions'] == val_set_SVM['set_label']
# SVM_errors_val = val_set_SVM[val_set_SVM['SVM Errors'] == False]
# len(SVM_errors_val)
# # SVC_errors_val.to_excel('SVC_errors_valset.xlsx')

# SVM_val_list = list(set(SVM_errors_val['name_activity'].to_list()))
# svm_val_errors_intersection = [name for name in name_500 if name in SVM_val_list]
# print(len(svm_val_errors_intersection))

# # test set
# test_set_SVM = test_content
# test_set_SVM['Predictions'] = pred_svm_test #add predictions from NB model to test instances
# test_set_SVM['SVM  Errors'] = test_set_SVM['Predictions'] == test_set_SVM['set_label']
# SVM_errors_test = test_set_SVM[test_set_SVM['SVM  Errors'] == False]
# len(SVM_errors_test)
# SVM_test_list = list(set(SVM_errors_test['name_activity'].to_list()))
# svm_test_errors_intersection = [name for name in name_500 if name in SVM_test_list]
# print(len(svm_test_errors_intersection))

