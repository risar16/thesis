{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as pyp\n",
    "import seaborn as sb\n",
    "import nltk\n",
    "\n",
    "#set working directory\n",
    "os.chdir('K:\\Specialemappe_XD1')\n",
    "\n",
    "# csv file obtained via R \n",
    "raw_data = pd.read_csv('emneraw.csv', sep=',', encoding='latin1')\n",
    "print(raw_data.columns)\n",
    "                   \n",
    "# find and remove NaN værdi\n",
    "raw_data.isnull().sum()\n",
    "np.where(raw_data['emne_fagbetegnelse'].isnull())[0]\n",
    "na_list = raw_data[raw_data['emne_fagbetegnelse'].isnull()].index.tolist()\n",
    "raw_data['emne_fagbetegnelse'][319147]\n",
    "print(raw_data.iloc[319147, :])\n",
    "print(raw_data.iloc[319148, :])\n",
    "print(raw_data.iloc[574995, :])\n",
    "print(raw_data.iloc[574996, :])\n",
    "print(raw_data.iloc[992314, :])\n",
    "print(raw_data.iloc[992315, :])\n",
    "\n",
    "#drop those index\n",
    "raw_data= raw_data.drop(index=[319147, 319148, 574995, 574996, 992314, 992315])\n",
    "\n",
    "# fix encoding errors\n",
    "raw_data['emne_fagbetegnelse'] = raw_data['emne_fagbetegnelse'].str.replace('Ã\\x98','Ø')\n",
    "raw_data['emne_fagbetegnelse'] = raw_data['emne_fagbetegnelse'].str.replace('Ã\\x86','Æ')\n",
    "raw_data['emne_fagbetegnelse'] = raw_data['emne_fagbetegnelse'].str.replace('Ã\\x85','Å')\n",
    "raw_data['emne_fagbetegnelse'] = raw_data['emne_fagbetegnelse'].str.replace('Â½','½')\n",
    "raw_data['emne_fagbetegnelse'] = raw_data['emne_fagbetegnelse'].str.replace('Â§','§')\n",
    "\n",
    "#drop useless column\n",
    "raw_data=raw_data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#rename columns\n",
    "raw_data = raw_data.rename(columns={\n",
    "                         'emne_fagbetegnelse':'emne_fag_navn', \n",
    "                         'ant_elever':'antal_elever',\n",
    "                         'ant_aktivitetid':'antal_gange_aktivitet'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activities based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns\n",
    "\n",
    "#ascending order\n",
    "df_sortedfq = raw_data.sort_values(by=['antal_gange_aktivitet'], ascending=False)\n",
    "df_sortedfq.reset_index(inplace=True)\n",
    "\n",
    "#   >5000 to millions - 2756 - 0.26%\n",
    "fq1 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] >= 5000)]\n",
    "\n",
    "#   >500 to 4999      - 61183 - 5.78%\n",
    "fq2 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] >= 500) & (df_sortedfq['antal_gange_aktivitet'] <5000)]\n",
    "\n",
    "#   >5 to 499        - 569340 - 53.80%\n",
    "fq3 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] >= 5) & (df_sortedfq['antal_gange_aktivitet'] <499)]\n",
    "\n",
    "#   >2 to 4          - 204794 - 19.35%\n",
    "fq4 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] >= 2) & (df_sortedfq['antal_gange_aktivitet'] <5)]\n",
    "\n",
    "#   1 time only      - 219878 - 20.78%\n",
    "fq5 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] == 1)]\n",
    "\n",
    "# snippet raw data in latex\n",
    "table1= df_sortedfq.loc[100:150]\n",
    "table1.columns\n",
    "table1=table1.drop(columns=['index', 'oversaettelse'])\n",
    "print(table1.to_latex(index=False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization: length of unique activity names\n",
    "\n",
    "# a) length raw strings\n",
    "raw_list =df_sortedfq['emne_fag_navn'].tolist()\n",
    "\n",
    "raw_length = []\n",
    "for i in range(len(raw_list)):\n",
    "    raw_length.append(len(raw_list[i]))\n",
    "\n",
    "#vis a)\n",
    "sb.set_theme(style=\"darkgrid\")\n",
    "ax_a= sb.displot(raw_length, binwidth=5, height=5)\n",
    "pyp.title(\"Length - characters\")\n",
    "ax_a.fig.set_figwidth(5)\n",
    "ax_a.fig.set_figheight(3)\n",
    "ax_a.savefig('length_raw.png', dpi=800)\n",
    "\n",
    "# b) length > 500 cleaned\n",
    "fq_more500 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] >= 500)]\n",
    "fq_more500_list = fq_more500['emne_fag_navn'].tolist()\n",
    "fqmore500_length = [len(fq_more500_list[i]) for i in range(len(fq_more500_list))]\n",
    "    \n",
    "#vis b)\n",
    "sb.set_theme(style=\"darkgrid\")\n",
    "ax_c= sb.displot(fqmore500_length, binwidth=5, height=5)\n",
    "pyp.title(\"Length - most occurring activities >> 500\")\n",
    "ax_c.fig.set_figwidth(5)\n",
    "ax_c.fig.set_figheight(3)\n",
    "ax_c.savefig('length_more500.png', dpi=800)\n",
    "\n",
    "\n",
    "# c) length  < 500 cleaned\n",
    "fq_less500 = df_sortedfq.loc[(df_sortedfq['antal_gange_aktivitet'] <500)]\n",
    "fq_less500_list = fq_less500['emne_fag_navn'].tolist()\n",
    "fqless500_length = [len(fq_less500_list[i]) for i in range(len(fq_less500_list))]\n",
    "\n",
    "#vis c)\n",
    "sb.set_theme(style=\"darkgrid\")\n",
    "ax_d= sb.displot(fqless500_length, binwidth=5, height=5)\n",
    "pyp.title(\"Length - less occurring activities < 500\")\n",
    "ax_d.fig.set_figwidth(5)\n",
    "ax_d.fig.set_figheight(3)\n",
    "ax_d.savefig('length_less500.png', dpi=800)\n",
    "ax_d.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unique activity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique abbreviations of activities registered by all schools\n",
    "raw_list = raw_data['emne_fag_navn'].tolist()\n",
    "unique_names = list(set(list_abbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization: how many potential short headlines per educational subject?\n",
    "\n",
    "obl_fag = ['dansk', 'historie', 'matematik', 'billedkunst', 'biologi', \n",
    "           'engelsk','fransk', 'fysik_kemi', 'geografi', 'madkundskab',\n",
    "           'håndværk_og_design', 'idræt', 'kristendomskundskab','musik',\n",
    "           'natur_teknologi','samfundsfag','tysk']\n",
    "length_fag = []  \n",
    "\n",
    "raw_l =    [l.lower() for l in unique_names]\n",
    "\n",
    "dan_l=      [label for label in raw_l if 'dan' in label] \n",
    "length_fag.append(len(dan_l))\n",
    "\n",
    "his_l=      [label for label in raw_l if 'his' in label]\n",
    "length_fag.append(len(his_l))\n",
    "\n",
    "mat_l=      [label for label in raw_l if 'mat' in label]\n",
    "length_fag.append(len(mat_l))\n",
    "\n",
    "bilk_l=     [label for label in raw_l if 'bil' in label]\n",
    "length_fag.append(len(bilk_l)) \n",
    "\n",
    "bio_l=      [label for label in raw_l if 'bio' in label]\n",
    "length_fag.append(len(bio_l)) \n",
    "\n",
    "eng_l=      [label for label in raw_l if 'eng' in label]\n",
    "length_fag.append(len(eng_l)) \n",
    "\n",
    "fr_l=       [label for label in raw_l if 'fra' in label]\n",
    "length_fag.append(len(fr_l)) \n",
    "\n",
    "fykemi_l=   [label for label in raw_l if 'fy' in label]\n",
    "length_fag.append(len(fykemi_l)) \n",
    "\n",
    "geo_l=     [label for label in raw_l if 'geo' in label]\n",
    "length_fag.append(len(geo_l)) \n",
    "\n",
    "madk_l=    [label for label in raw_l if 'mad' in label]\n",
    "length_fag.append(len(madk_l)) \n",
    "\n",
    "hdes_l=    [label for label in raw_l if 'hå' in label]\n",
    "length_fag.append(len(hdes_l)) \n",
    "\n",
    "idr_l=      [label for label in raw_l if 'idr' in label]\n",
    "length_fag.append(len(idr_l)) \n",
    "\n",
    "krins_l=    [label for label in raw_l if 'kri' in label]\n",
    "length_fag.append(len(krins_l)) \n",
    "\n",
    "mus_l=      [label for label in raw_l if 'mus' in label]\n",
    "length_fag.append(len(mus_l)) \n",
    "\n",
    "natek_l=  [label for label in raw_l if 'nat' in label]\n",
    "length_fag.append(len(natek_l)) \n",
    "\n",
    "samf_l=     [label for label in raw_l if 'sam' in label]\n",
    "length_fag.append(len(samf_l)) \n",
    "\n",
    "tys_l=     [label for label in raw_l if 'tys' in label]\n",
    "length_fag.append(len(tys_l)) \n",
    "\n",
    "# merge fag and length by zip().  \n",
    "list_tuples = list(zip(obl_fag, length_fag))  \n",
    "print(list_tuples)  \n",
    "  \n",
    "# Converting lists of tuples into Dataframe.  \n",
    "df_fag = pd.DataFrame(list_tuples, columns=['Fag', 'Number of instances'])  \n",
    "print(df_fag)  \n",
    "total_fag = df_fag['Number of instances'].sum()\n",
    "#vis\n",
    "pyp.figure(figsize=(8,12), dpi=1200)\n",
    "ax_e=sb.barplot(y =\"Fag\",\n",
    "                x =\"Number of instances\", \n",
    "                palette=\"Blues_d\", orient= 'h',\n",
    "                data = df_fag.sort_values(by=['Number of instances'], ascending=False))\n",
    "\n",
    "pyp.title(\"No. of activities per subject name; total 48696, 20.7%\")\n",
    "pyp.savefig('subjectnames_bins.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example how to use pandas and concatenate / merge\n",
    "\n",
    "\n",
    "\n",
    "# example for merging three different regex search and getting 'øvrige' examples\n",
    "new_df = df.loc[(~df[\"emne_fag_navn\"].str.contains('MAT'))\n",
    "                          & (~df[\"emne_fag_navn\"].str.contains('DAN'))\n",
    "                          & (~df[\"emne_fag_navn\"].str.contains('ENG'))]\n",
    "sample_df = new_df.sample(n=3360, random_state=100)\n",
    "sample_df['hånd_validering'] = ' '\n",
    "sample_df.reset_index(inplace = True, drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### how do we check a single activity name and contact a school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all data entries for a specific abbrevations in str.contains('')\n",
    "\n",
    "check_df = raw_data\n",
    "#lowercasing for better view\n",
    "check_df['emne_fag_navn']= c_df['emne_fag_navn'].apply(lambda x: x.lower())\n",
    "\n",
    "single_check = check_df.loc[(raw_data['emne_fag_navn'].str.contains('DAN16B'))]\n",
    "\n",
    "# using index \n",
    "check_df.loc[6644]\n",
    "\n",
    "# count how many times is present (remember the redundancy of non-unique names)\n",
    "check_df['emne_fag_navn'].str.contains('COVID').sum()\n",
    "\n",
    "#identify school by institutionnummer on the institutionsregister\n",
    "# https://data.stil.dk/InstregV2/Fremfind.aspx?InstNr=743002&SearchType=Inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: random sample of 52000 unique activity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique abbreviations of activities registered by all schools\n",
    "list_activities = raw_data['emne_fag_navn'].tolist()\n",
    "print(len(list_activities))\n",
    "unique_activities = list(set(unique_activities))\n",
    "print(len(unique_activities))\n",
    "\n",
    "# df_unique_activities = pd.DataFrame(unique_activities, columns = ['emne_fag_navn'])\n",
    "#print out excel data\n",
    "# df_unique_activities.to_excel('df_211k_instances.xlsx')\n",
    "\n",
    "\n",
    "# draw a random sample\n",
    "# random.seed(1)\n",
    "# random.shuffle(unique_abbr)\n",
    "# sample_activities = random.sample(unique_activities, 52000)\n",
    "\n",
    "# #dataframe and xlxs for labelling manually\n",
    "# sample_df = pd.DataFrame(sample_activities, columns=['emne_fag_navn'])\n",
    "# sample_df.reset_index(inplace=True)\n",
    "# sample_df['set_label']= ' '\n",
    "\n",
    "#print excel file for manual labelling\n",
    "# sample_df.to_excel('sample52k.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the sample file is renamed to \"labelled_sample\" once manual labelling is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that setting the labels is correct without mistakes\n",
    "load_sample=pd.read_excel('sample52k.xlsx')\n",
    "load_sample =load_sample.drop(columns=['Unnamed: 0'])\n",
    "load_sample['set_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remaining unique activity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique activity names remaining from the 52k \n",
    "remaining_istances = [instance for instance in unique_abbr if instance not in abbr_52k_list]\n",
    "print(len(remaining_istances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### draw additional 10 random samples from the remaining activity names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 159795 remaining unique names\n",
    "\n",
    "#211795 unique abbreviations of activities registered by all schools\n",
    "list_all = raw_data['emne_fag_navn'].tolist()\n",
    "list_abbr = list(map(str, list_all))\n",
    "unique_abbr = list(set(list_all))\n",
    "\n",
    "# load unique abbreviation of activities from sample selected previously\n",
    "load_sample=pd.read_excel('sample52k.xlsx')\n",
    "load_sample.columns\n",
    "load_sample['set_label'].value_counts()\n",
    "\n",
    "#detect float element\n",
    "# float_check = pd.to_numeric(load_sample['emne_fag_navn'],errors='coerce').notna()\n",
    "\n",
    "all_abbr_sample52 = load_sample['emne_fag_navn'].tolist()\n",
    "list_abbr_sample52 = list(map(str, all_abbr_sample52))\n",
    "unique_abbr_sample52 =list(set(list_abbr_sample52))\n",
    "len(unique_abbr_sample52) # 2 activities have been deleted since not recognized by schools\n",
    "\n",
    "#filter name activities without those in the trained sample\n",
    "filtered1 = [i for i in unique_abbr if i not in unique_abbr_sample52]\n",
    "print(len(filtered1)) #159842\n",
    "\n",
    "# draw 10 samples of 100 instances\n",
    "random.seed(2)\n",
    "random.shuffle(filtered1)\n",
    "#1\n",
    "sample_test1 = random.sample(filtered1,100)\n",
    "#2\n",
    "filtered2 =  [i for i in filtered1 if i not in sample_test1]\n",
    "print(len(filtered2))\n",
    "sample_test2 = random.sample(filtered2,100)\n",
    "#3\n",
    "filtered3 =  [i for i in filtered1 if i not in sample_test2]\n",
    "print(len(filtered3))\n",
    "sample_test3 = random.sample(filtered3,100)\n",
    "#4\n",
    "filtered4 =  [i for i in filtered3 if i not in sample_test3]\n",
    "print(len(filtered4))\n",
    "sample_test4 = random.sample(filtered4,100)\n",
    "#5\n",
    "filtered5 =  [i for i in filtered4 if i not in sample_test4]\n",
    "print(len(filtered5))\n",
    "sample_test5 = random.sample(filtered5,100)\n",
    "#6\n",
    "filtered6 =  [i for i in filtered5 if i not in sample_test5]\n",
    "print(len(filtered6))\n",
    "sample_test6 = random.sample(filtered6,100)\n",
    "#7\n",
    "filtered7 =  [i for i in filtered6 if i not in sample_test6]\n",
    "print(len(filtered7))\n",
    "sample_test7 = random.sample(filtered7,100)\n",
    "#8\n",
    "filtered8 =  [i for i in filtered7 if i not in sample_test7]\n",
    "print(len(filtered8))\n",
    "sample_test8 = random.sample(filtered8,100)\n",
    "#9\n",
    "filtered9 =  [i for i in filtered8 if i not in sample_test8]\n",
    "print(len(filtered9))\n",
    "sample_test9 = random.sample(filtered9,100)\n",
    "#10\n",
    "filtered10 =  [i for i in filtered9 if i not in sample_test9]\n",
    "print(len(filtered10))\n",
    "sample_test10 = random.sample(filtered10,100)\n",
    "\n",
    "# #dataframe and xlxs for samples\n",
    "#import itertools\n",
    "list_samples = list(itertools.chain(sample_test1,sample_test2,sample_test3,sample_test4, sample_test5,\\\n",
    "                                    sample_test6,sample_test7, sample_test8, sample_test9, sample_test10))\n",
    "\n",
    "samples_df = pd.DataFrame(list_samples, columns=['emne_fag_navn'])\n",
    "samples_df.reset_index(inplace=True)\n",
    "samples_df['set_label']= ' '\n",
    "\n",
    "# samples_df.to_excel('10samplessave.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inspecting noise within the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe with the only column of names\n",
    "content = pd.DataFrame(update_data['emne_fagbetegnelse'])\n",
    "content.shape\n",
    "content.loc[50:70]\n",
    "print(len(content.loc[50][0]))\n",
    "\n",
    "#removing digits 0-9 that occur 1 or more times in the labels [column]\n",
    "content['emne_fagbetegnelse'] = content['emne_fagbetegnelse'].str.replace('\\d+', '')\n",
    "content.loc[50:70]\n",
    "print(len(content.loc[50][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex recap\n",
    "strs = \"how much for the maple syrup? $20.99? That's ricidulous!!!\"\n",
    "print (strs)\n",
    "nstr = re.sub(r'[?|$|.|!]',r'',strs)\n",
    "print (nstr)\n",
    "nestr = re.sub(r'[^a-zA-Z0-9 ]',r'',nstr)\n",
    "print (nestr)\n",
    "\n",
    "import re\n",
    "d=' ''3A LEJRSKOLE - NORMALTIMER /BO -.- .-. ./.V - MAT., ./. ÅRGANG 2022 ???? \\\\\\\\\\\\ $$$'\n",
    "print(d)\n",
    "d= re.sub('-', r'', d)\n",
    "print(d)\n",
    "d=re.sub(r'[?|$|.|!|\\|/|]',r'',d)\n",
    "print(d)\n",
    "d = re.sub('\\W+','', d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### which kind of noise do we find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with all instances including a specific noise\n",
    "noise_check = load_sample.loc[(load_sample['emne_fag_navn'].str.contains('*'))]\n",
    "\n",
    "#reporting found noise\n",
    "#  \" \" , ' ', (), %, ,* . ,.., // , / , ?, ??, multiple??, @, _ ,  +, >, §§BD A, § space, .-., \n",
    "#  different format of ´´ -> ‘’EKSAMENSVAGT FP  ´, ¨SFO, ¨.Å, ` AH, ”MIG OG MIN ROBOT”, \n",
    "#  ½,  melleumru usage x4 \n",
    "#- _  -- ---  - (BORTFALDER)\n",
    "#( ) { } ambiguous count\n",
    "#() 0{} 0[]\n",
    "# [*]\n",
    "#[´] [`] [\"] [#] 6[@] [,] [;] [:] [.] [<>]\n",
    "#! _?_ [?] \\W+ ?\n",
    "#[+-] 0~ 0[|]\n",
    "# [0123456789] 130k: 0 21k, 1 31k, 2 18k, 3 14k, 4 13k, 5 11k, 6 10k, 7 9k, 8 8k, 9 6k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usage of numbers, -, whitespaces is quite diverse. \n",
    "\n",
    "Noise and characters are close to or merget to meaningful abbreviations and words. \n",
    "\n",
    "It makes sense to replace with a whitespace all these characters and numbers \n",
    "to help tokenization.\n",
    "\n",
    "If / replaced by whitespace we get two words or two characters or two abbreviations for fysik/kemi, natur/teknologi, håndværk/design.\n",
    "\n",
    "In case of N/T makes sense to replace in natur teknologi (formal language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use NLTK 3.6.5 instead of NLTK 3.6.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verify what happens with tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [          
    "content = df['emne_fag_navn'] #variable containing name activities\n",
    "\n",
    "content_text=[] \n",
    "for name in content:                \n",
    "    name = name.lower()               #lowercasing\n",
    "    # a bug introduced in NLTK 3.6.6 > IndexError: list index out of range\n",
    "    # needs to remove . ! ? any end-of-sentence characters\n",
    "    name = name.replace(\"!\", '')    #removing all !\n",
    "    name = name.replace(\"?\", '')    #removing all *\n",
    "    name = name.replace(\".\", '')    #removing all *\n",
    "    # name = name.replace(\",\", '')    #removing all ,\n",
    "    name = nltk.word_tokenize(name, language= 'danish')\n",
    "    \n",
    "    for piece in name:\n",
    "        if piece != ' ':\n",
    "            content_text.append(piece)\n",
    "print('Sample of the output')\n",
    "print(content_text[0:5])\n",
    "print(content_text[5:10])\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "print(\"Number of words:\", len(content_text))\n",
    "print(\"Number of unique words:\", len(set(content_text)))\n",
    "print(\"Lexical diversity:\", round(lexical_diversity(content_text), 4))\n",
    "\n",
    "#collocations are expressions og multiple words which commonly co-occur, more often than singularly\n",
    "bigrams = BigramCollocationFinder.from_words(content_text)  #bigrams \n",
    "collocation = bigrams.nbest(BigramAssocMeasures.likelihood_ratio, 50)\n",
    "collocation\n",
    "\n",
    "bigrams_freq = list(nltk.bigrams(content_text))\n",
    "bigr_freq = nltk.FreqDist(bigrams_freq)\n",
    "bigr_freq.plot(10)\n",
    "print(\"Most frequent bigrams\")\n",
    "\n",
    "print(\"Right: most frequent bigrams; Left: most frequent collocations\")\n",
    "list(zip(collocation, bigr_freq)) #there´s difference between most freq collocations and bigrams\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
