{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import pickle\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import nltk             \n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# setting directory\n",
    "os.chdir('K:\\Specialemappe_XD1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labelled sample\n",
    "load_sample=pd.read_excel('labelled_sample.xlsx')\n",
    "load_sample.columns\n",
    "\n",
    "# identify any NaN values\n",
    "load_sample.isnull().values.any()\n",
    "\n",
    "# deleting 187 instances not recognized by educational institutions or with mixed classes\n",
    "rows_to_delete = load_sample.loc[load_sample['instances_to_discard']=='delete']\n",
    "load_sample.drop(load_sample.loc[load_sample['instances_to_discard']=='delete'].index, inplace=True)\n",
    "\n",
    "# data dropping drop useless columns\n",
    "df = load_sample.drop(columns=['Unnamed: 0', 'index', 'instances_to_discard'])\n",
    "df.columns\n",
    "\n",
    "# count instances per classes\n",
    "df['set_label'].value_counts()\n",
    "\n",
    "# set interested classes with integer labels \n",
    "df.loc[df['set_label'] == 'dansk', 'set_label'] = 1\n",
    "df.loc[df['set_label'] == 'idræt', 'set_label'] = 2\n",
    "df.loc[df['set_label'] == 'matematik', 'set_label'] = 3\n",
    "df.loc[df['set_label'] == 'temporary', 'set_label'] = 4\n",
    "df.loc[df['set_label'] == 'other', 'set_label'] = 0\n",
    "\n",
    "# set all other classes as the class '0'\n",
    "df['set_label'] = np.where(\n",
    "    (df['set_label'] !=1) & (df['set_label'] !=2) & (df['set_label'] !=3) & (df['set_label'] !=4), 0, df['set_label'])\n",
    "df\n",
    "# class imbalance \n",
    "df['set_label'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction on non pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable containing name activities\n",
    "content = df['name_activity']\n",
    "\n",
    "# text composed by the name of the activites from which word features can be obtained\n",
    "content_text=[]\n",
    "\n",
    "# variable containing Danish stopwords\n",
    "dansk_stopwords = set(stopwords.words('danish'))\n",
    "\n",
    "for name in content:\n",
    "     #lowercasing\n",
    "    name = name.lower()\n",
    "    # substitute with whitespace to make possible a better tokenization\n",
    "    name = re.sub('[-_()\\\"#@;:`.''!?*´:;,<>=+^]', ' ', name)\n",
    "    # substitute with whitespace to make possible a better tokenization\n",
    "    name = re.sub('[4578]', ' ', name) \n",
    "    #tokenizing \n",
    "    name = word_tokenize(name, language= 'danish')\n",
    "    \n",
    "    for token in name:\n",
    "        if token != ' ':\n",
    "            if token != '':\n",
    "                if token not in dansk_stopwords:\n",
    "                    content_text.append(token)\n",
    "\n",
    "print('Example of the output:')\n",
    "print(content_text[100:150])\n",
    "\n",
    "# variable containing the most frequent words\n",
    "distribution_used_words = nltk.FreqDist(w for w in content_text) \n",
    "\n",
    "# feature selector\n",
    "def document_features(document, word_features):\n",
    "    \n",
    "        document_words = set(document)\n",
    "        features = {}\n",
    "        for word in word_features :\n",
    "            features['contains ({})'.format(word)] = (word in document_words)\n",
    "        return features\n",
    "\n",
    "# word features\n",
    "most_fq_words = nltk.FreqDist(w for w in content_text) \n",
    "word_features_400 = list(most_fq_words)[:400]\n",
    "\n",
    "# additional features\n",
    "rule_based_features = [\n",
    "    'matematikkens', 'geogebra', 'ing', 'svø', 'vø', 'svøm',\\\n",
    "    'atletik', 'basket','kids', 'kidsvolley', 'volley', 'motion',\\\n",
    "    'da2','dsa', 'andet','andetsprog', 'dansk andet sprog',\\\n",
    "    '0.', 'børnhave', 'basis', 'basisdansk',\\\n",
    "    'fp9','pf9', 'eksam',\\\n",
    "    'planlægning','a0','16d', '16b', '§16', '§',\\\n",
    "    'ffmat', 'ffdan', 'klassemøde', 'læringssamtale', 'fasa', 'konference'\\\n",
    "    'vej', 'vejledning', 'læsevejledere', 'matematikvejleder', 'idrv', 'matv'\\\n",
    "    'vikar', 'eks'\n",
    "    'skal ikke', 'kørsel', 'studietur', 'kommunale', 'fælleskommnunal','skoleintro', 'praktik']\n",
    "\n",
    "word_features_all = list(itertools.chain(word_features_400, rule_based_features))\n",
    "\n",
    "#save features with noise data\n",
    "# with open('all_features_noise', 'wb') as fp:\n",
    "#     pickle.dump(word_features_all, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% splitting data and datasets building\n",
    "\n",
    "def train_val_test(text,cutoffs=[0.8,0.9]):\n",
    "    train = text[:int(len(text)*cutoffs[0])]\n",
    "    val = text[int(len(text)*cutoffs[0]):int(len(text)*cutoffs[1])]\n",
    "    test = text[int(len(text)*cutoffs[1]):]\n",
    "    return train, val, test\n",
    "\n",
    "train_content, val_content, test_content = train_val_test(df)\n",
    "train_content['set_label'].value_counts()   # number of instances >= 655 per class\n",
    "val_content['set_label'].value_counts()     # number of instances >= 71 per class\n",
    "test_content['set_label'].value_counts()    # number of instances >= 85 per class\n",
    " \n",
    "#training set building TUPLE\n",
    "train_data_tuple = (train_content['name_activity'], train_content['set_label']) #create dataframe tuple\n",
    "set_training=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in train_data_tuple[0]:\n",
    "    set_training.append([(i.iloc[counter]) for i in train_data_tuple]) #append name emne and its label as a tuple\n",
    "    counter+=1\n",
    "    \n",
    "#validation set building TUPLE\n",
    "val_data_tuple = (val_content['name_activity'], val_content['set_label']) #create dataframe tuple\n",
    "set_validation=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in val_data_tuple[0]:\n",
    "    set_validation.append([(i.iloc[counter]) for i in val_data_tuple]) #append name emne and its label as a tuple\n",
    "    counter+=1\n",
    "\n",
    "#test set building TUPLE\n",
    "test_data_tuple=(test_content['name_activity'], test_content['set_label']) #create dataframe tuple\n",
    "set_test=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in test_data_tuple[0]:\n",
    "    set_test.append([(i.iloc[counter]) for i in test_data_tuple]) #append name emne and its label as a tuple\n",
    "    counter+=1\n",
    "\n",
    "print(\"Training tuple length:\", len(set_training))\n",
    "print(\"Validation tuple length:\", len(set_validation))\n",
    "print(\"Test tuple length:\", len(set_test))\n",
    "\n",
    "\n",
    "train_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_all), label) \n",
    "             for w, label in set_training]# Training set - def document_feature on each string and pair with class\n",
    "\n",
    "val_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_all), label) \n",
    "           for w, label in set_validation]# Validation set - def document_feature on each string and pair with class \n",
    "\n",
    "test_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_all), label) \n",
    "            for w, label in set_test]# Test set - def document_feature on each string and pair with class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier: Naive Bayes on noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfNB = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# classes\n",
    "target_names = ['0','1','2', '3', '4'] \n",
    "\n",
    "# performance on validation set\n",
    "y_val = [(y) for _, y in val_set]\n",
    "pred_NB_val = [clfNB.classify(p) for p, _ in val_set]\n",
    "f1_NB_val = f1_score(y_val, pred_NB_val, average='macro')\n",
    "print(\"F1-Score val_set:\", round(f1_NB_val, 4),\"\\n\")\n",
    "confusion_matrix(y_val, pred_NB_val)\n",
    "# Print classification report\n",
    "print(classification_report(y_val, pred_NB_val, target_names=target_names))\n",
    "\n",
    "#performance on test set\n",
    "y_test = [(y) for _, y in test_set]\n",
    "pred_NB_test = [clfNB.classify(p) for p, _ in test_set]\n",
    "f1_NB_test = f1_score(y_test, pred_NB_test, average='macro') \n",
    "print(\"F1-Score test_set:\", round(f1_NB_test, 4),\"\\n\")\n",
    "confusion_matrix(y_test, pred_NB_test)\n",
    "# Print classification report\n",
    "print(classification_report(y_test, pred_NB_test, target_names=target_names))\n",
    "\n",
    "## save model\n",
    "# with open('NB_notcleaned.pickle', 'wb') as f:\n",
    "#     pickle.dump(clfNB, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier: Logistic regression on noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights after grid search\n",
    "weights_log = {0: 0.44, 1: 0.56, 2: 0.56, 3: 0.56, 4:0.56}\n",
    "\n",
    "clfLOG = SklearnClassifier(LogisticRegression(random_state = 10,\n",
    "                                               multi_class='ovr',\n",
    "                                               penalty='l2',\n",
    "                                               class_weight=weights_log)).train(train_set)\n",
    "\n",
    "\n",
    "# performance on validation set\n",
    "y_val = [(y) for _, y in val_set]\n",
    "pred_log_val = [clfLOG.classify(p) for p, _ in val_set]\n",
    "f1_log_val = f1_score(y_val, pred_log_val, average='macro')\n",
    "print(\"F1-Score val_set:\", round(f1_log_val, 4),\"\\n\")\n",
    "confusion_matrix(y_val, pred_log_val)\n",
    "print(classification_report(y_val, pred_log_val, target_names=target_names))\n",
    "\n",
    "\n",
    "# performance on test set\n",
    "y_test = [(y) for _, y in test_set]\n",
    "pred_log_test = [clfLOG.classify(p) for p, _ in test_set]\n",
    "f1_log_test = f1_score(y_test, pred_log_test, average='macro') \n",
    "print(\"F1-Score test_set:\", round(f1_log_test, 4),\"\\n\")\n",
    "confusion_matrix(y_test, pred_log_test)\n",
    "print(classification_report(y_test, pred_log_test, target_names=target_names))\n",
    "\n",
    "\n",
    "# # save model\n",
    "# with open('LOG_notcleaned.pickle', 'wb') as f:\n",
    "#     pickle.dump(clfLOG, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier : SVM on noise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights after grid search\n",
    "weights_svm = {0: 0.11,1: 0.89, 2: 0.89,3: 0.89, 4: 0.89}\n",
    "\n",
    "clfSVM = SklearnClassifier(LinearSVC(random_state=10, \n",
    "                                     C=1.8,\n",
    "                                     penalty = 'l2',\n",
    "                                     loss = 'hinge',\n",
    "                                     multi_class='ovr',\n",
    "                                     class_weight=weights_svm)).train(train_set)\n",
    "\n",
    "# performance on validation set\n",
    "y_val = [(y) for _, y in val_set]\n",
    "pred_svm_val= [clfSVM.classify(p) for p, _ in val_set]\n",
    "f1_svm_val = f1_score(y_val, pred_svm_val, average='macro')\n",
    "print(\"F1-Score val_set:\", round(f1_svm_val, 4),\"\\n\")\n",
    "# confusion_matrix(y_val, pred_svm_val)\n",
    "print(classification_report(y_val, pred_svm_val, target_names=target_names))\n",
    "\n",
    "# performance on test set\n",
    "y_test = [(y) for _, y in test_set]\n",
    "pred_svm_test = [clfSVM.classify(p) for p, _ in test_set]\n",
    "f1_svm_test = f1_score(y_test, pred_svm_test, average='macro') \n",
    "print(\"F1-Score test_set:\", round(f1_svm_test, 4),\"\\n\")\n",
    "# confusion_matrix(y_test, pred_svm_test)\n",
    "print(classification_report(y_test, pred_svm_test, target_names=target_names))\n",
    "\n",
    "# save model\n",
    "#with open('SVM_notcleaned.pickle', 'wb') as f:\n",
    "#    pickle.dump(clfSVM, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
