{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in prompt set NLTK in the environment and check its operativity\n",
    "# set NLTK_DATA=H:\\nltk_data\n",
    "\n",
    "#import libraries\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.metrics import ConfusionMatrix\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import compute_class_weight \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# setting directory\n",
    "os.chdir('K:\\Specialemappe_XD1')\n",
    "\n",
    "# load labelled sample\n",
    "load_sample=pd.read_excel('labelled_sample.xlsx')\n",
    "\n",
    "# deleting instances not recognized by educational institutions or with mixed classes\n",
    "load_sample.drop(load_sample.loc[load_sample['instances_to_discard']=='delete'].index, inplace=True)\n",
    "\n",
    "# data dropping drop useless columns\n",
    "df = load_sample.drop(columns=['Unnamed: 0', 'index', 'instances_to_discard'])\n",
    "\n",
    "# set interested classes with integer labels \n",
    "df.loc[df['set_label'] == 'dansk', 'set_label'] = 1\n",
    "df.loc[df['set_label'] == 'idræt', 'set_label'] = 2\n",
    "df.loc[df['set_label'] == 'matematik', 'set_label'] = 3\n",
    "df.loc[df['set_label'] == 'temporary', 'set_label'] = 4\n",
    "df.loc[df['set_label'] == 'other', 'set_label'] = 0\n",
    "\n",
    "# set all other classes to the class 'other'\n",
    "df['set_label'] = np.where(\n",
    "    (df['set_label'] !=1) & (df['set_label'] !=2) & (df['set_label'] !=3) & (df['set_label'] !=4), 0, df['set_label'])\n",
    "\n",
    "# class imbalance 0 = 43674, 1 = 888, 2 = 810 , 3 = 950, 4 = 5491\n",
    "df['set_label'].value_counts()\n",
    "\n",
    "# cleaning data \n",
    "char_noise = r'[-_()\\\"#@;:`.''!?*´.:;,<>=+^Â/]' # - _ / Â are serious issues\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: re.sub(char_noise, ' ', x))\n",
    "\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: x.replace('  ', ' '))\n",
    "# needed a 2nd time\n",
    "df['name_activity']= df['name_activity'].apply(lambda x: x.replace('  ', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% generate word features\n",
    "\n",
    "# data content\n",
    "content = df['name_activity']\n",
    "\n",
    "dansk_stopwords = set(stopwords.words('danish'))\n",
    "\n",
    "cleaned_content_text=[]\n",
    "for name in content:\n",
    "    name = name.lower()                                      #lowercasing\n",
    "    name = re.sub('[-_()\\\"#@;:`.''!?*´:;,<>=+^]', ' ', name) # substitute with whitespace to help tokenizing\n",
    "    name = re.sub('[4578]', ' ', name)                      # substitute with whitespace to help tokenizing\n",
    "    name = word_tokenize(name, language= 'danish')           #tokenize name activities\n",
    "    for token in name:\n",
    "        if token != ' ':\n",
    "            if token != '':\n",
    "                if token not in dansk_stopwords:\n",
    "                    cleaned_content_text.append(token)\n",
    "\n",
    "print('Sample of the output')\n",
    "print(cleaned_content_text[100:150])\n",
    "\n",
    "most_fq_words_cleaned = nltk.FreqDist(w for w in cleaned_content_text) \n",
    "word_features_cleaned = list(most_fq_words_cleaned)[:400]\n",
    "\n",
    "#additional features\n",
    "strings_rule = (\n",
    "    'matematikkens', 'geogebra', 'ing', 'svø', 'vø', 'svøm', 'svømning',\\\n",
    "    'atletik', 'basket','kids', 'kidsvolley', 'volley', 'motion', 'motionsdag',\\\n",
    "    '0', 'bhk', 'børnhave', \\\n",
    "    'eks', 'dækkes','skal ikke', 'kørsel', 'studietur','tur', 'kommunale', 'fælleskommnunal'\\\n",
    "    'prøve', 'terminsprøve', 'fp9','pf9', 'test','eksam',\\\n",
    "    '16', '16d', '16b', '§16',\\\n",
    "    'skoleintro', 'praktik', 'sfo', 'planlægning',\\\n",
    "    'ff', 'fagteam','kursus', 'klassemøde', 'møde', 'netværksmøde', 'læringssamtale', 'fase', 'fasa',\\\n",
    "    'vej', 'vejleder','vejledning', 'læsevejledere', 'matematikvejleder',\\\n",
    "    'konference','webinar', 'studietur'\\\n",
    "    'vikar','vikartime', 'vikartimer',\\\n",
    "    'da','da2', 'som', 'dansk som','andet', 'dansk som andetsprog', 'dansk som andet sprog','dsa')\n",
    "\n",
    "additional_features=list(strings_rule)\n",
    "\n",
    "for i in additional_features:\n",
    "    word_features_cleaned.append(i)\n",
    "    print(len(word_features_cleaned))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data and datasets building\n",
    "\n",
    "def train_val_test(text,cutoffs=[0.8,0.9]):\n",
    "    train = text[:int(len(text)*cutoffs[0])]\n",
    "    val = text[int(len(text)*cutoffs[0]):int(len(text)*cutoffs[1])]\n",
    "    test = text[int(len(text)*cutoffs[1]):]\n",
    "    return train, val, test\n",
    "\n",
    "train_content, val_content, test_content = train_val_test(df)\n",
    "train_content['set_label'].value_counts()   #  >775 per class\n",
    "val_content['set_label'].value_counts()     # >89 perr class\n",
    "test_content['set_label'].value_counts()    # >99 per class\n",
    " \n",
    "#training set building TUPLE\n",
    "train_data_tuple = (train_content['name_activity'], train_content['set_label']) #create dataframe tuple\n",
    "set_training=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in train_data_tuple[0]:\n",
    "    set_training.append([(i.iloc[counter]) for i in train_data_tuple]) #append name and its label as a tuple\n",
    "    counter+=1\n",
    "    \n",
    "#validation set building TUPLE\n",
    "val_data_tuple = (val_content['name_activity'], val_content['set_label']) #create dataframe tuple\n",
    "set_validation=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in val_data_tuple[0]:\n",
    "    set_validation.append([(i.iloc[counter]) for i in val_data_tuple]) #append name and its label as a tuple\n",
    "    counter+=1\n",
    "\n",
    "#test set building TUPLE\n",
    "test_data_tuple=(test_content['name_activity'], test_content['set_label']) #create dataframe tuple\n",
    "set_test=[]\n",
    "counter=0 #used for indexing\n",
    "for _ in test_data_tuple[0]:\n",
    "    set_test.append([(i.iloc[counter]) for i in test_data_tuple]) #append name and its label as a tuple\n",
    "    counter+=1\n",
    "\n",
    "print(\"Training tuple length:\", len(set_training))\n",
    "print(\"Validation tuple length:\", len(set_validation))\n",
    "print(\"Test tuple length:\", len(set_test))\n",
    "\n",
    "def document_features(document, word_features):\n",
    "        document_words = set(document)\n",
    "        features = {}\n",
    "        # for word in word_features :\n",
    "        for word in word_features_cleaned :\n",
    "            features['contains ({})'.format(word)] = (word in document_words)\n",
    "        return features\n",
    "\n",
    "train_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_cleaned), label) \n",
    "             for w, label in set_training]# Training set - def document_feature on each string and pair with class\n",
    "\n",
    "val_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_cleaned), label) \n",
    "           for w, label in set_validation]# Validation set - def document_feature on each string and pair with class \n",
    "\n",
    "test_set = [(document_features(word_tokenize(w.lower(), language='danish'),word_features_cleaned), label) \n",
    "            for w, label in set_test]# Test set - def document_feature on each string and pair with class\n",
    "    \n",
    "print(\"Training set length:\", len(train_set))\n",
    "print(\"Validation set length:\", len(val_set))\n",
    "print(\"Test set length:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search class weights with Logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_weights = np.linspace(0.1,0.99,100)\n",
    "grid_parameters = {'class_weight': [{0:x, 1:1.0-x, 2:1.0-x, 3:1.0-x, 4:1.0-x} for x in potential_weights]}\n",
    "\n",
    "# tracking time\n",
    "start_time_log = datetime.now()\n",
    "\n",
    "# list to store the results\n",
    "results_from_weights_log = []\n",
    "counting = 0 \n",
    "for weigths in grid_parameters.values():\n",
    "    for parameters in weigths: \n",
    "        counting += 1     \n",
    "        classifier = SklearnClassifier(LogisticRegression(random_state = 10,\n",
    "                                                       multi_class='ovr',\n",
    "                                                       penalty='l2',\n",
    "                                                       class_weight=parameters)).train(train_set)\n",
    "        y_train = [(y) for _, y in train_set]\n",
    "        y_val = [(y) for _, y in val_set]\n",
    "        pred_clf_train = [classifier.classify(p) for p, _ in train_set]\n",
    "        pred_clf_val = [classifier.classify(p) for p, _ in val_set]\n",
    "        scoring_train = f1_score(y_train, pred_clf_train, average='macro')\n",
    "        scoring_val = f1_score(y_val, pred_clf_val, average='macro')\n",
    "        print(counting)\n",
    "        results_from_weights_log.append([parameters, scoring_train, scoring_val])\n",
    "    \n",
    "# dataframe to look better the results\n",
    "results_dataframe_log = pd.DataFrame(results_from_weights_log, \n",
    "                                     columns = [\"LOGweights\", \"F1-Score train\", \"F1-Score val\"])\n",
    "\n",
    "# time needed to search class weights\n",
    "end_time_log = datetime.now()\n",
    "duration_log = start_time_log - end_time_log \n",
    "duration_in_s_log = duration_log.total_seconds()*(-1) \n",
    "duration_in_h_log = duration_in_s_log //3600\n",
    "duration_in_m_log = (duration_in_s_log %3600) //60\n",
    "print('The search of the right weights for the five classes needed', '%d:%d' \\\n",
    "      %(duration_in_h_log,duration_in_m_log), 'in terms of hours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### restricted weight search with Logistic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reistricted search \n",
    "restricted_range_weights_= np.array(\n",
    "    [0.31, 0.32, 0.33, 0.34, 0.35,0.36,0.37,0.38,0.39,0.40,0.41,0.42,0.43,0.44,\\\n",
    "     0.45,0.46,0.47,0.48,0.49,0.50,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,\\\n",
    "         0.60,0.61,0.62,0.63,0.64,0.65])\n",
    "    \n",
    "grid_parameters2 = {'class_weight': [{0:x, 1:1.0-x, 2:1.0-x, 3:1.0-x, 4:1.0-x} for x in restricted_range_weights_]}\n",
    "\n",
    "# tracking time\n",
    "start_time_log2 = datetime.now()\n",
    "\n",
    "# list to store the results\n",
    "results_from_weights_log2 = []\n",
    "counting = 0 \n",
    "for weigths in grid_parameters2.values():\n",
    "    for parameters in weigths: \n",
    "        counting += 1     \n",
    "        classifier = SklearnClassifier(LogisticRegression(random_state = 10,\n",
    "                                                       multi_class='ovr',\n",
    "                                                       penalty='l2',\n",
    "                                                       class_weight=parameters)).train(train_set)\n",
    "\n",
    "        y_train = [(y) for _, y in train_set]\n",
    "        y_val = [(y) for _, y in val_set]\n",
    "        pred_clf_train = [classifier.classify(p) for p, _ in train_set]\n",
    "        pred_clf_val = [classifier.classify(p) for p, _ in val_set]\n",
    "        scoring_train = f1_score(y_train, pred_clf_train, average='macro')\n",
    "        scoring_val = f1_score(y_val, pred_clf_val, average='macro')\n",
    "        print(counting)\n",
    "        results_from_weights_log2.append([parameters, scoring_train, scoring_val])\n",
    "\n",
    "# dataframe to look better the results\n",
    "results_dataframe_log2= pd.DataFrame(results_from_weights_log2, \n",
    "                                     columns = [\"LOGweights\", \"F1-Score train\", \"F1-Score val\"])\n",
    "\n",
    "# time needed to search class weights\n",
    "end_time_log2 = datetime.now()\n",
    "duration_log2 = start_time_log2 - end_time_log2 \n",
    "duration_in_s_log2 = duration_log2.total_seconds()*(-1) \n",
    "duration_in_h_log2 = duration_in_s_log2 //3600\n",
    "duration_in_m_log2 = (duration_in_s_log2 %3600) //60\n",
    "print('The search of the right weights for the five classes needed', '%d:%d' \\\n",
    "      %(duration_in_h_log2,duration_in_m_log2), 'in terms of hours')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search class weights with SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial grid search\n",
    "\n",
    "# generate 100 values as parameters to test\n",
    "potential_weights = np.linspace(0.1,0.99,100)\n",
    "grid_parameters = {'class_weight': [{0:x, 1:1.0-x, 2:1.0-x, 3:1.0-x, 4:1.0-x} for x in potential_weights]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = [(y) for _, y in val_set]\n",
    "rstate = 10 \n",
    "Cs = [0.01,0.1,0.2, 0.3, 0.4,0.5,0.6, 0.7, 0.8, 0.9, 1.0,1.1, 1.2, 1.3, 1.4 ,1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1,2.2,2.3,2.4,2.5]\n",
    "\n",
    "# second grid search\n",
    "restricted_range_weights_svc= np.array(\n",
    "    [0.10, 0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2, 0.21, 0.22, 0.22, 0.23, 0.24,\\\n",
    "     0.25, 0.26, 0.27, 0.28, 0.29, 0.30, 0,31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\\\n",
    "     0.39, 0.40, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.50])\n",
    "    \n",
    "grid_parameters_svc = {'class_weight': [{0:x, 1:1.0-x, 2:1.0-x, 3:1.0-x, 4:1.0-x} for x in restricted_range_weights_svc]}\n",
    "\n",
    "\n",
    "results_search_hinge =[]\n",
    "\n",
    "# tracking time \n",
    "start_time_search2 = datetime.now()\n",
    "counting = 0 \n",
    "\n",
    "for c in Cs:\n",
    "        for weight in weights_svc:\n",
    "            counting += 1  \n",
    "            svc_current = SklearnClassifier(LinearSVC(random_state = 10, \n",
    "                                                      max_iter= 200, \n",
    "                                                      penalty = 'l2',\n",
    "                                                      loss = 'hinge',\n",
    "                                                      multi_class = 'ovr',\n",
    "                                                      class_weight = parameter, \n",
    "                                                      C = c)).train(train_set)\n",
    "            \n",
    "            pred_val= [svc_current.classify(p) for p, _ in val_set]\n",
    "            scoring_val = f1_score(y_val, pred_val, average='macro')\n",
    "            print(counting)\n",
    "            results_search_hinge.append([weight, c, scoring_val])\n",
    "\n",
    "end_time_search2 = datetime.now()\n",
    "duration_search2 = start_time_search2 - end_time_search2\n",
    "duration_s_search2= duration_search2.total_seconds()*(-1) \n",
    "duration_in_m_svc2 = (duration_s_search2 %3600) //60\n",
    "print('The search of the best parameter C needed,', duration_in_m_svc2, 'minutes')\n",
    "# dataframe to look better the results\n",
    "results_search_svc_hinge= pd.DataFrame(results_search_hinge,columns = ['Weights','C', 'F1-Score val'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes about the best class weights according to F1-Macro score in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================NOTES=================================================\n",
    "\n",
    "# first attempt LOG \n",
    "# val : 0.9167\n",
    "# {0: 0.4236363636363637, 1: 0.5763636363636363, 2: 0.5763636363636363, 3: 0.5763636363636363, 4: 0.5763636363636363}\n",
    "# {0: 0.4326262626262627, 1: 0.5673737373737373, 2: 0.5673737373737373, 3: 0.5673737373737373, 4: 0.5673737373737373}\n",
    "# {0: 0.4416161616161617, 1: 0.5583838383838383, 2: 0.5583838383838383, 3: 0.5583838383838383, 4: 0.5583838383838383}\n",
    "\n",
    "# second attempt LOG \n",
    "# val 0.9267\n",
    "# {0: 0.44, 1: 0.56, 2: 0.56, 3: 0.56, 4: 0.56}\n",
    "\n",
    "# first attempt SVC \n",
    "# val : 0.9367\n",
    "# {0: 0.11797979797979799, 1: 0.882020202020202, 2: 0.882020202020202, 3: 0.882020202020202, 4: 0.882020202020202}\n",
    "# {0: 0.12696969696969698, 1: 0.873030303030303, 2: 0.873030303030303, 3: 0.873030303030303, 4: 0.873030303030303}\n",
    "\n",
    "\n",
    "# second attempt SVC\n",
    "# val : 0.9467\n",
    "# best C = 1.8\n",
    "# {0: 0.11, 1: 0.89, 2: 0.89, 3: 0.89, 4: 0.89}\n",
    "# {0: 0.11797979797979799, 1: 0.882020202020202, 2: 0.882020202020202, 3: 0.882020202020202, 4: 0.882020202020202}\n",
    "\n",
    "# ============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
